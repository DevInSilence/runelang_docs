## Core Introduction

To build the core of our project, we need to establish a solid foundation by implementing essential components. We will start by setting up a basic lexer, followed by writing unit tests to ensure its functionality. Once basic lexing is functional, we'll proceed to develop the parser. The parser will be gradually expanded by implementing one expression or statement at a time.

## Roadmap

### 1. Setup Lexer

**Goal:** Establish the foundational components for tokenizing the input.

- **Location:** Implement a system to track the position of tokens within the source code.
- **TokenKind (TKind):** Define different kinds of basic tokentypes (e.g., numbers, identifiers, keywords).
- **Token:** Create a structure to represent individual tokens, including their type, value, and location.
- **Lexer:** Develop the main lexer class/function to scan through the input and generate a stream of tokens.

more to come...
